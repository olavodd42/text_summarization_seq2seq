{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a658bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 21:17:13.514996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753834634.211499    7149 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753834634.377487    7149 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753834635.947466    7149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753834635.947519    7149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753834635.947523    7149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753834635.947527    7149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 21:17:16.095268: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention\n",
    "\n",
    "vocab_size_input = 10000 + 1\n",
    "vocab_size_output = 6000 + 1\n",
    "embedding_dim = 128\n",
    "units=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc21c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753834662.442389    7149 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1794 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# ENCODER LAYERS\n",
    "encoder_inputs = Input(shape=(100,))\n",
    "enc_emb = Embedding(input_dim=vocab_size_input, output_dim=embedding_dim)(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# DECODER LAYERS\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(vocab_size_output, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# ATTENTION LAYERS\n",
    "attention = Attention()\n",
    "context_vector = attention([decoder_outputs, encoder_output])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size_output, activation='softmax'))\n",
    "final_output = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f055e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1Score(y_true, y_pred):\n",
    "    # y_true: (batch_size, seq_len)\n",
    "    # y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    vocab_size = tf.shape(y_pred)[-1]\n",
    "\n",
    "    # One-hot encode y_true to match y_pred's shape\n",
    "    y_true_oh = tf.one_hot(y_true, depth=vocab_size)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Convert y_pred to binary predictions (argmax)\n",
    "    y_pred_bin = tf.one_hot(tf.argmax(y_pred, axis=-1), depth=vocab_size)\n",
    "\n",
    "    tp = tf.reduce_sum(y_true_oh * y_pred_bin)\n",
    "    fp = tf.reduce_sum((1 - y_true_oh) * y_pred_bin)\n",
    "    fn = tf.reduce_sum(y_true_oh * (1 - y_pred_bin))\n",
    "\n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2d8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\toptimizer=tf.keras.optimizers.AdamW(learning_rate=1e-3),\n",
    "\tloss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "\tmetrics=['accuracy', 'precision', 'recall', F1Score, 'AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86b75ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros que você usou na outra sessão\n",
    "BATCH = 16384         # ou outro valor que você tenha definido\n",
    "MAXLEN_DOC = 100      # comprimento da sequência do document\n",
    "MAXLEN_SUM = 30       # comprimento da sequência do summary\n",
    "\n",
    "# Reconstrua o element_spec manualmente:\n",
    "element_spec = {\n",
    "    'document': tf.TensorSpec(shape=(BATCH, MAXLEN_DOC), dtype=tf.int64),\n",
    "    'summary' : tf.TensorSpec(shape=(BATCH, MAXLEN_SUM),  dtype=tf.int64),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcaf2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.load(\n",
    "    \"vectorized_gigaword_ds\",\n",
    "    element_spec=element_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9312b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_LoadDataset element_spec={'document': TensorSpec(shape=(16384, 100), dtype=tf.int64, name=None), 'summary': TensorSpec(shape=(16384, 30), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8356d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "SHUFFLE_BUFFER   = 10000\n",
    "BATCH_SIZE       = 64\n",
    "\n",
    "def make_training_example(x):\n",
    "    enc_in = x['document']                         # (MAXLEN_DOC,)\n",
    "    dec_in = x['summary'][:-1]                     # (MAXLEN_SUM-1,)\n",
    "    dec_tr = x['summary'][1:]                      # (MAXLEN_SUM-1,)\n",
    "    return ( (enc_in, dec_in), dec_tr )\n",
    "\n",
    "paired = ds.map(make_training_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "shuffled = paired.shuffle(SHUFFLE_BUFFER, reshuffle_each_iteration=False)\n",
    "total = tf.data.experimental.cardinality(shuffled).numpy()\n",
    "val_count = int(total * VALIDATION_SPLIT)\n",
    "\n",
    "val_ds = (\n",
    "    shuffled\n",
    "    .take(val_count)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "train_ds = (\n",
    "    shuffled\n",
    "    .skip(val_count)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b09aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 19:04:45.027012: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in ds.take(1):\n",
    "\tprint(batch['document'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: (64, 100)\n",
      "Decoder input shape: (64, 29)\n",
      "Target shape: (64, 29)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attr 'Toutput_types' of 'OptionalFromValue' Op passed list of length 0 less than minimum 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs should be a tuple of (encoder_input, decoder_input)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size mismatch between inputs and targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/dados/miniconda3/envs/ia/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/dados/miniconda3/envs/ia/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:132\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     empty_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Attr 'Toutput_types' of 'OptionalFromValue' Op passed list of length 0 less than minimum 1."
     ]
    }
   ],
   "source": [
    "# Debug: print a batch from train_ds to check shapes\n",
    "for (inputs, targets) in train_ds.take(1):\n",
    "    print(\"Encoder input shape:\", inputs[0].shape)\n",
    "    print(\"Decoder input shape:\", inputs[1].shape)\n",
    "    print(\"Target shape:\", targets.shape)\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=30,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4839450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: (64, 100)\n",
      "Decoder input shape: (64, 29)\n",
      "Target shape: (64, 29)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, targets) in train_ds.take(1):\n",
    "    print(\"Encoder input shape:\", inputs[0].shape)\n",
    "    print(\"Decoder input shape:\", inputs[1].shape)\n",
    "    print(\"Target shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bb2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
